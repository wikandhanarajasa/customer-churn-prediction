# -*- coding: utf-8 -*-
"""Copy of FP Telecom_Solution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W2grGhWY1VCh5BnybX60J_96mJWMBwbJ

#**Analysis of Churn Customer**

##Introduction

Interconnect is telecomunication company that focus on landline and internet service. Aside from those two services, it also offers other service such as Internet Security, Tech Support, Cloud Storage, Online Backup and Streaming Service.

In order to maintain the business stays profitable, the company decided to deepen analize their customers by forecast their churn rate. Any potential churn client will be offer promotion code and special package to keep them using the service.

The marketing team has been gathered the data needed to run the analysis such as client information, contract and current service.

##Goal

The goals of this project are as below:
1. Having a proper machine learning model to predict client churn with AUC-ROC as main metric with score exceeding or equal to 0.88.
2. Having F1 score as additional metric.
3. Having statistic calculation and visualization the findings.
4. Having comparation behaviour of telephone and internet users.

##Steps

The steps of this project are as below:
1. Load the data and study the general information.
2. Prepare the data if anomalies were found & check the class balance.
3. Create machine learning model & train the model while maintain AUC-ROC score above or equal to 0.88.
4. Draw the conclusion.

####Data Loadment
"""

pip install xgboost

pip install catboost

# Data Manipulation and Analysis Libraries
import pandas as pd
import numpy as np

# Data Visualization Libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning Libraries
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score
from sklearn.utils import shuffle
from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder
import xgboost as xgb
from scipy.stats import uniform, randint
import lightgbm as lgb
from catboost import CatBoostClassifier
from sklearn.svm import SVC

#Loading Dataset
path_contract = '/content/contract.csv'
path_personal = '/content/personal.csv'
path_internet = '/content/internet.csv'
path_phone = '/content/phone.csv'

data_contract = pd.read_csv(path_contract)
data_personal = pd.read_csv(path_personal)
data_internet = pd.read_csv(path_internet)
data_phone = pd.read_csv(path_phone)

"""#####Data Contract

Understand and checking the general information of the data and looking for anomalies of data contract.
"""

data_contract.head(3)

data_contract.shape

data_contract.info()

data_contract.isnull().sum()

data_contract.duplicated().sum()

"""Based on data exploratory in the first chapter, we don't need to change the date format in begin_date and end_date, but we have to convert the value in total_charges into float64 format.


"""

data_contract.columns = ['customer_id',
                         'begin_date',
                         'end_date', 'type',
                         'paperless_billing',
                         'payment_method',
                         'monthly_charges',
                         'total_charges']

data_contract['total_charges'] = pd.to_numeric(data_contract['total_charges'], errors='coerce').astype('float64')

data_contract.head(2)

data_contract.info()

"""#####Data Personal

Understand and checking the general information of the data and looking for anomalies of data personal.
"""

data_personal.head(3)

data_personal.shape

data_personal.info()

data_personal['SeniorCitizen'].unique()

data_personal.duplicated().sum()

data_personal.isnull().sum()

"""Based on data exploratory in the first chapter, the data is already good and we just need to set the column name into proper style."""

data_personal.columns = ['customer_id',
                         'gender',
                         'senior_citizen',
                         'partner',
                         'dependents']

data_personal.head(2)

"""#####Data Internet

Understand and checking the general information of the data and looking for anomalies of data internet.
"""

data_internet.head(2)

data_internet.shape

data_internet.info()

data_internet.duplicated().sum()

data_internet.isnull().sum()

"""Based on data exploratory in the first chapter, the data is already good and we just need to set the column name into proper style."""

data_internet.columns = ['customer_id',
                         'internet_service',
                         'online_security',
                         'online_backup',
                         'device_protection',
                         'tech_support',
                         'streaming_tv',
                         'streaming_movies']

data_internet.head(2)

"""#####Data Phone

Understand and checking the general information of the data and looking for anomalies of data personal.
"""

data_phone.head(3)

data_phone.shape

data_phone.info()

data_phone.duplicated().sum()

data_phone.isnull().sum()

"""Based on data exploratory in the first chapter, the data is already good and we just need to set the column name into proper style."""

data_phone.columns = ['customer_id', 'multiple_lines']

data_phone.head(2)

"""####Feature Engineering

In this stage we will shape the data given into one single dataset that fit for machine learning. Those step are as below:
1. Merge all data into one dataset.
2. Drop unecessary column(s).
3. One hot encoding to turns categorical data into boolean.
4. Split the data into feature and target.
5. Split the data into train set and test set.

#####Data Merging
"""

data_contract.info()

data = pd.merge(data_contract, data_internet, on='customer_id', how='left')

#Merged data of data_contract and data_internet
data.info()

data = pd.merge(data, data_personal, on='customer_id', how='left')

#Merged data of data_contract, data_internet and data_personal
data.info()

data = pd.merge(data, data_phone, on='customer_id', how='left')

#Merged data of data_contract, data_personal, data_internet and data_phone
data.info()

data.isnull().sum()

data = data.dropna(subset=['total_charges'])

data.isnull().sum()

data.head(2)

"""Filling the null values with "No" because these customers are not using any of the services mentioned above."""

data = data.fillna('No')
data.isnull().sum()

"""Creating column churn in order to indicate churn customer where value 0 means active customer and value 1 means churn customer"""

data['churn'] = data['end_date'].apply(lambda x: 0 if x == 'No' else 1)

data.shape

data['churn'].unique()

data.head(2)

data.info()

plt.figure(figsize=(4, 2))
sns.countplot(x='churn', data=data)
plt.show()

"""#####Data Dropping"""

#Droping unecessary columns
data = data.drop(['customer_id', 'begin_date', 'end_date'], axis=1)
data.head(2)

"""#####One Hot Encoding"""

scaler = MinMaxScaler()
data[['total_charges', 'monthly_charges']] = scaler.fit_transform(data[['total_charges', 'monthly_charges']])

categorical_columns = data.select_dtypes(include=['object']).columns
encoder = OrdinalEncoder()
data[categorical_columns] = encoder.fit_transform(data[categorical_columns])

data.head(2)

data.duplicated().sum()

data = data.drop_duplicates()

data.duplicated().sum()

data.info()

"""#####Determining Feature and Target"""

#X where its features data
#y where its target data

X = data.drop(['churn'], axis=1)
y = data['churn']

X.head(2)

X.info()

y.head(2)

y.info()

"""#####Splitting Train and Test dataset"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

X_train.shape

X_test.shape

y_train.shape

y_test.shape

"""####Developping Machine Learning Model"""

def class_eval(model, X_train, X_test, y_train, y_test):
    # Machine Learning Model
    ml_model = model.__class__.__name__

    # Predict Train
    y_train_pred = model.predict(X_train)

    # Predict Test
    y_test_pred = model.predict(X_test)

    # Predict Probabilities for ROC AUC score
    y_train_pred_proba = model.predict_proba(X_train)[:, 1]
    y_test_pred_proba = model.predict_proba(X_test)[:, 1]

    # ROC AUC score
    roc_auc_train = round(roc_auc_score(y_train, y_train_pred_proba) * 100, 2)
    roc_auc_test = round(roc_auc_score(y_test, y_test_pred_proba) * 100, 2)

    # Precision
    precision_train = round(precision_score(y_train, y_train_pred) * 100, 2)
    precision_test = round(precision_score(y_test, y_test_pred) * 100, 2)

    # F1 Score
    f1_score_train = round(f1_score(y_train, y_train_pred) * 100, 2)
    f1_score_test = round(f1_score(y_test, y_test_pred) * 100, 2)

    # Create DataFrame for results
    ml_result = pd.DataFrame({
        'model': [ml_model],
        'roc_auc_train': [roc_auc_train],
        'roc_auc_test': [roc_auc_test],
        'precision_train': [precision_train],
        'precision_test': [precision_test],
        'f1_score_train': [f1_score_train],
        'f1_score_test': [f1_score_test]
    })

    return ml_result

"""#####Logistic Regression

Performing hyperparameter tuning for a Logistic Regression model using GridSearchCV to find the best parameters based on the ROC AUC score.
"""

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 3, 10],
    'solver': ['lbfgs', 'liblinear'],
    'max_iter': [100, 500, 1000],
    'random_state': [12, 42, 12345]
}

# Initialize the Logistic Regression model
lr_model = LogisticRegression(random_state=123)

# Initialize GridSearchCV with the Logistic Regression model and the parameter grid
grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)

# Fit the model to find the best hyperparameters
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_lr = grid_search.best_estimator_

# Print the best parameters
print(f"Best parameters found: {grid_search.best_params_}")

lr_model = class_eval(best_lr, X_train, X_test, y_train, y_test)
lr_model

"""#####Random Forest Classifier

Performing hyperparameter tuning for a Random Forest Classifier model using GridSearchCV to find the best parameters based on the ROC AUC score
"""

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 11, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False],
}

# Initialize the RandomForestClassifier model
rf_model = RandomForestClassifier(random_state=42)

# Initialize GridSearchCV with the RandomForestClassifier model and the parameter grid
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)

# Fit the model to find the best hyperparameters
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_rf = grid_search.best_estimator_

# Print the best parameters
print(f"Best parameters found: {grid_search.best_params_}")

rf_model = class_eval(best_rf, X_train, X_test, y_train, y_test)
rf_model

"""#####Decision Tree Classifier

Performing hyperparameter tuning for a Decision Tree Classifier model using GridSearchCV to find the best parameters based on the ROC AUC score
"""

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'max_depth': [3, 5, 7, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

# Initialize the DecisionTreeClassifier model
dt_model = DecisionTreeClassifier(random_state=42)

# Initialize GridSearchCV with the DecisionTreeClassifier model and the parameter grid
grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)

# Fit the model to find the best hyperparameters
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_dt = grid_search.best_estimator_

# Print the best parameters
print(f"Best parameters found: {grid_search.best_params_}")

dt_model = class_eval(best_dt, X_train, X_test, y_train, y_test)
dt_model

"""#####X Gradient Boost Classifier

Performing hyperparameter tuning for a X Gradient Boost Classifier model using GridSearchCV to find the best parameters based on the ROC AUC score
"""

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

# Initialize the XG Boost Classifier model
xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False)

# Initialize GridSearchCV with the XGBoost model and the parameter grid
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)

# Fit the model to find the best hyperparameters
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_xgb = grid_search.best_estimator_

# Print the best parameters
print(f"Best parameters found: {grid_search.best_params_}")

xgb_model = class_eval(best_xgb, X_train, X_test, y_train, y_test)
xgb_model

"""#####Light Gradient Boosting Classifier

Performing hyperparameter tuning for a Light Gradient Boost Classifier model using GridSearchCV to find the best parameters based on the ROC AUC score
"""

# Define the parameter grid for hyperparameter tuning
param_grid_lgb = {
    'num_leaves': [31, 41, 51],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200, 300],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

# Define the LightGBM model
lgb_model = lgb.LGBMClassifier(random_state=42)

# Initialize GridSearchCV with the LightGBM model and the parameter grid
grid_search_lgb = GridSearchCV(estimator=lgb_model, param_grid=param_grid_lgb, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)

# Fit the model to find the best hyperparameters
grid_search_lgb.fit(X_train, y_train)

# Get the best model from the grid search
best_lgb = grid_search_lgb.best_estimator_

# Print the best parameters
print(f"Best parameters found for LightGBM: {grid_search_lgb.best_params_}")

lgb_model = class_eval(best_lgb, X_train, X_test, y_train, y_test)
lgb_model

"""#####Cat Boost Classifier

Performing hyperparameter tuning for a Cat Gradient Boost Classifier model using GridSearchCV to find the best parameters based on the ROC AUC score
"""

# Define the parameter grid for hyperparameter tuning
param_grid_cat = {
    'depth': [3, 4, 5],
    'learning_rate': [0.01, 0.05, 0.1],
    'iterations': [100, 200, 300],
    'l2_leaf_reg': [1, 3, 5],
    'bagging_temperature': [0.8, 1, 1.2]
}

# Define the CatBoost model
cat_model = CatBoostClassifier(random_state=42, verbose=0)

# Initialize GridSearchCV with the CatBoost model and the parameter grid
grid_search_cat = GridSearchCV(estimator=cat_model, param_grid=param_grid_cat, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)

# Fit the model to find the best hyperparameters
grid_search_cat.fit(X_train, y_train)

# Get the best model from the grid search
best_cat = grid_search_cat.best_estimator_

# Print the best parameters
print(f"Best parameters found for CatBoost: {grid_search_cat.best_params_}")

cat_model = class_eval(best_cat, X_train, X_test, y_train, y_test)
cat_model

"""#####Gradient Boosting Classifier

Performing hyperparameter tuning for a Gradient Boost Classifier model using GridSearchCV to find the best parameters based on the ROC AUC score
"""

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize the Gradient Boosting Classifier model
gbm_model = GradientBoostingClassifier(random_state=42)

# Initialize GridSearchCV with the Gradient Boosting model and the parameter grid
grid_search = GridSearchCV(estimator=gbm_model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)

# Fit the model to find the best hyperparameters
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_gbm = grid_search.best_estimator_

# Print the best parameters
print(f"Best parameters found: {grid_search.best_params_}")

gbm_model = class_eval(best_gbm, X_train, X_test, y_train, y_test)
gbm_model

"""####Result"""

result_all = pd.concat([lr_model, rf_model, dt_model, xgb_model, lgb_model, cat_model, gbm_model], ignore_index=True)
result_all = result_all.sort_values(by='roc_auc_test', ascending=False)
result_all

"""####Summary

The performance of various machine learning models for predicting customer churn was evaluated based on ROC AUC, precision, and F1 scores. **The Gradient Boosting Classifier** emerged as the top performer with an ROC AUC of **85.88%** and an F1 score of **57.04%** on the test set. The CatBoost Classifier followed closely with an ROC AUC of 85.85% and an F1 score of 56.74%.

The Gradient Boosting Classifier achieved a strong ROC AUC score of 85.88%, indicating good discrimination between churn and non-churn customers. However, its F1 score of 57.04% suggests that while it performs well overall, its balance between precision and recall needs improvement. This performance is particularly notable given the **imbalanced dataset**, where only 1 in 4 customers are churners.
"""